---
layout: post
title: "灰度共生矩阵(Grey Level Co-occurrence Matrix, GLCM)"
date: 2019-07-29 19:13:00 +0800
categories: 图像处理
mathjax: true
figure: ./images/2019-7/ception.png
author: Jarvis
meta: Post
---

* content
{:toc}



## 纹理特征

粗糙, 柔和, 凹凸不平这些词汇常用来描述人对某些材质的触感, 这种触感是由于材质表面的颗粒高低不平的幅度导致的. 不同大小的手指触碰到不同的材质(材料表面高低点的差距和其空间距离)会产生不同的触感. 

下图是一种粗糙的质感.

{% include image.html class="polaroid" url="2019-7/texture-1.jpg" title="粗糙的纹理" %}

下图是一种光滑, 柔和的质感.

{% include image.html class="polaroid" url="2019-7/texture-2.jpg" title="光滑的纹理" %}

图像的纹理是类似的, 材料表面的高低不同的点反映在图像中是像素值也称为灰度值(grey levels, GL). 而用手指触碰材料的一块区域在图像中用一个方框表示, 探测一个小方框内的纹理信息, 方框的大小可以按需求定义.

## GLCM 灰度共生矩阵 

为了简单我们使用一个大小为 $$ 4\times 4 $$ 的灰度图, 像素值用 2bit 表示, 即只有四种取值 0, 1, 2, 3. 如下图所示.

{% include image.html class="polaroid" url="2019-7/texture-3.jpg" title="示例图片" %}

对应每个像素的灰度值为

$$
\begin{matrix}
0 & 0 & 1 & 1 \\
0 & 0 & 1 & 1 \\
0 & 2 & 2 & 2 \\
2 & 2 & 3 & 3 \\
\end{matrix}
$$

GLCM 纹理特征考虑的是**固定位置关系**的两个像素值在图像中出现的频率. 比如考虑 (1, 0) 位置关系, 把它看作一个向量, 那么向量的头尾恰好对应了图像中的两个具有该位置关系的像素. 如下图, (红色-->蓝色) 表示的就是像素值对, 在选定 (1, 0) 位置关系时的 GLCM 统计的就是所有可能出现的像素值对在图像中出现的频率. 

$$
\begin{matrix}
0 & \color{red}{0} & \color{blue}{1} & 1 \\
\color{red}{0} & \color{blue}{0} & 1 & 1 \\
0 & 2 & \color{red}{2} & \color{blue}{2} \\
2 & 2 & 3 & 3 \\
\end{matrix}
$$

由于我们这里的像素值只有四种选择, 因此所有的像素值对的频率可以形成一个 $$ 4\times4 $$ 的矩阵. 我们把第一个像素称为**参考像素**, 第二个像素称为**邻居像素**. 我们统计一下像素值对 `(0, 0)`, `(0, 1)`, `(2, 2)` 出现的数量

$$
\begin{matrix}
\color{green}{0} & \color{green}{0} & 1 & 1 \\
\color{green}{0} & \color{green}{0} & 1 & 1 \\
0 & 2 & 2 & 2 \\
2 & 2 & 3 & 3 \\
\end{matrix}\qquad\qquad
\begin{matrix}
0 & \color{blue}{0} & \color{blue}{1} & 1 \\
0 & \color{blue}{0} & \color{blue}{1} & 1 \\
0 & 2 & 2 & 2 \\
2 & 2 & 3 & 3 \\
\end{matrix}\qquad\qquad
\begin{matrix}
0 & 0 & 1 & 1 \\
0 & 1 & 1 & 1 \\
0 & \color{red}{2} & \color{red}{2} & \color{red}{2} \\
\color{red}{2} & \color{red}{2} & 3 & 3 \\
\end{matrix}
$$

`(0, 0)` 出现了<font color="green">两次</font>, `(0, 1)`出现了<font color="blue">两次</font>, `(2, 2)`出现了<font color="red">三次</font>. 因此上图对于 (1, 0) 位置关系的 GLCM 为

$$
\begin{equation}\label{eq:1}
\begin{array}{c|cccc}
 & 0 & 1 & 2 & 3 \\ \hline
0 & \color{green}{2} & \color{blue}{2} & 1 & 0 \\
1 & 0 & 2 & 0 & 0 \\
2 & 0 & 0 & \color{red}{3} & 1 \\
3 & 0 & 0 & 0 & 1 \\
\end{array}\end{equation}
$$

其中左边一列表示像素值对中的参考像素, 上边一行表示邻居像素, 中间的矩阵为 GLC 矩阵. 

## GLCM 的特性

1. GLCM 是方阵, 因为参考像素的取值范围和邻居像素的取值范围一样.
2. GLCM 的行数和列数等于图像像素值的灰度范围. 如果使用量化技术, 则等于量化后的等级数量. 比如示例图像是 2bit 的, 那么灰度等级有 $$ 2^2=4 $$ 个. 通常的灰度图像是 8bit 的, 灰度等级有 $$ 2^8=256 $$ 个, 那么 GLCM 就是一个 $$ 256\times256 $$ 的矩阵. 
3. 我们希望 GLCM 是对称阵, 这样方便纹理特征的计算, 因此为了使 GLCM 是对称阵, 只需要在使用位置关系 `(1, 0)` 时把位置关系 `(0, 1)` 的也加到一起即可. 为了简单计算, 只需要把 $$ \eqref{eq:1} $$ 式加上其转置矩阵即可:

$$
\begin{equation}\label{eq:2}
\begin{array}{c|cccc}
 & 0 & 1 & 2 & 3 \\ \hline
0 & 4 & 2 & 1 & 0 \\
1 & 2 & 4 & 0 & 0 \\
2 & 1 & 0 & 6 & 1 \\
3 & 0 & 0 & 1 & 2 \\
\end{array}\end{equation}
$$

### 把 GLCM 表示为概率

表示为概率的办法就是对 GLCM 进行归一化:

$$
P_{ij} = \frac{e_{i,j}}{\sum_{m,n=0}^{N-1}e_{m,n}}.
$$

因此 $$ \eqref{eq:2} $$ 式的归一化矩阵形式为

$$
\begin{equation}\begin{array}{c|cccc}
 & 0 & 1 & 2 & 3 \\ \hline
0 & 0.166 & 0.083 & 0.042 & 0 \\
1 & 0.083 & 0.166 & 0 & 0 \\
2 & 0.042 & 0 & 0.250 & 0.042 \\
3 & 0 & 0 & 0.042 & 0.083 \\
\end{array}\end{equation}
$$

* 对角元表示像素值对元素相等, 如果对角线上是高概率值则表明图像整体的灰度变化不大. 
* 次对角线(这是平行于对角线的线)上表示像素值相差为 1 的像素对, 再次的对角线上为像素值相差为 2 的像素对, 依次类推, 离对角线越远, 则表示像素值对的灰度差距越大

### GLDV: Grey-Level Difference Vector

GLDV 就是 GLDM 平行于对角线的线上的元素之和. 比如 $$ \eqref{eq:2} $$ 式的 GLDV 和归一化矩阵 GLDV 如下表所示

$$
\begin{equation}\begin{array}{c|c|c}
 \text{像素对之差} & \text{出现的次数} & \text{归一化} \\ \hline
0 & 16 & 0.666 \\
1 & 6 & 0.250 \\
2 & 2 & 0.083 \\
3 & 0 & 0 \\
\end{array}\end{equation}
$$

从 GLDV 中可以看出示例图像中绝大部分都是和邻居像素值相等的像素对, 少部分突变在不同的像素区域之间产生. 

## 参考文献

[^1]:
    **Going Deeper with Convolutions**<br />
    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, et al. <br />
    [[link]](https://arxiv.org/abs/1409.4842). In CVPR[C], 2015: 1-9.

[^2]:
    **Batch normalization: Accelerating deep network training by reducing internal covariate shift**<br />
    Sergey Ioffe, Christian Szegedy <br />
    [[link]](https://arxiv.org/abs/1502.03167). In arXiv, 1502.03167.
